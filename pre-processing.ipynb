{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2c809c",
   "metadata": {},
   "source": [
    "# Pre-processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e03b59",
   "metadata": {},
   "source": [
    "# Part 1: Making a python script that iterates all my csv files inside a folder and drops unnecessary columns in all of them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e768bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - Obtaining all csv files in the folder: \n",
    "\n",
    "folder_path = r\"specific_folder\"\n",
    "\n",
    "csv_files = glob.glob(folder_path + \"/*.csv\")\n",
    "\n",
    "\n",
    "# 1.2 - Iterate over each CSV file and execute the code.\n",
    "\n",
    "for file_path in csv_files:\n",
    "    # Load the csv file into a Pandas Dataframe using \"cp1252\" encoding \n",
    "    df = pd.read_csv(file_path, sep=\";\", encoding=\"cp1252\")\n",
    "\n",
    "    # Drop columns 'DESCRICAO_APRESENTACAO', 'CONSELHO_PRESCRITOR', 'UF_CONSELHO_PRESCRITOR'\n",
    "    columns_to_drop = ['DESCRICAO_APRESENTACAO', 'CONSELHO_PRESCRITOR', 'UF_CONSELHO_PRESCRITOR']\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file.\n",
    "    output_file_path = file_path[:-4] + \"_modified.csv\"  # Adiciona \"_modified\" ao nome do arquivo\n",
    "    df.to_csv(output_file_path, index=False, sep=\";\", encoding=\"cp1252\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd9e21",
   "metadata": {},
   "source": [
    "# Part 2: Finding max column lenghts to create trustworthy target table in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cf5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ANO_VENDA': 4, 'MES_VENDA': 2, 'UF_VENDA': 2, 'MUNICIPIO_VENDA': 32, 'PRINCIPIO_ATIVO': 602, 'QTD_VENDIDA': 7, 'UNIDADE_MEDIDA': 6, 'TIPO_RECEITUARIO': 3, 'CID10': 4, 'SEXO': 3, 'IDADE': 5, 'UNIDADE_IDADE': 3}\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the maximum length of each value in a column\n",
    "def max_length(column):\n",
    "    return max(len(str(value)) for value in column)\n",
    "\n",
    "# Initialize a dictionary to store the maximum lengths for each column\n",
    "column_lengths = {}\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Suppress DtypeWarning using the warnings module\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path, sep=';', encoding='cp1252')\n",
    "\n",
    "        # Calculate the maximum length for each column in the current dataframe\n",
    "        for col in df.columns:\n",
    "            col_max_length = max_length(df[col])\n",
    "            # Check if the column is already in the dictionary and update the maximum length if necessary\n",
    "            if col in column_lengths:\n",
    "                column_lengths[col] = max(column_lengths[col], col_max_length)\n",
    "            else:\n",
    "                column_lengths[col] = col_max_length\n",
    "\n",
    "# Show the maximum lengths of each column across all dataframes\n",
    "print(column_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe59522",
   "metadata": {},
   "source": [
    "# Part 3: Creating a table for double checking after inserting data into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b943ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# 1.2 - Iterate over each CSV file and execute the code.\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        # Load the csv file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path, sep=\";\", encoding=\"cp1252\")\n",
    "\n",
    "        # Get the number of rows in the DataFrame\n",
    "        row_count = df.shape[0]\n",
    "\n",
    "        # Extract the year and month from the file name directly\n",
    "        file_name = os.path.basename(file_path)\n",
    "        year = int(file_name.split(\"_\")[2][:4])\n",
    "        month = int(file_name.split(\"_\")[2][4:6])\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append((year, month, row_count))\n",
    "    except pandas.errors.ParserError as e:  # Change pd.errors.ParserError to pandas.errors.ParserError\n",
    "        print(f\"Error reading file: {file_path} - {e}\")\n",
    "\n",
    "# Create a new DataFrame from the results list\n",
    "columns = ['year', 'month', 'count']\n",
    "new_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_file_path = r\"(...)\\matching_table00.csv\"\n",
    "new_df.to_csv(output_file_path, index=False, sep=\";\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b62ea",
   "metadata": {},
   "source": [
    "# Part 4: Checking for duplicates before importing to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86441df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found:\n",
      "    year  month    count\n",
      "77  2020      6  5362515\n",
      "78  2020      7  5362515\n"
     ]
    }
   ],
   "source": [
    "file_path02 = r\"C:\\Users\\ninol\\Desktop\\PROFESSIONAL\\DATA_STORAGE\\MEDICAMENTOS\\matching_table00.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file_path02, sep=\";\", encoding=\"cp1252\")\n",
    "\n",
    "duplicates = df2[df2['count'].duplicated(keep=False)]  # keep parameter returns both duplicates\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates found:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf413d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
